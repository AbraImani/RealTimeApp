import streamlit as st
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS
import io
from collections import Counter
import re

# Importer le client Gemini si l'extraction de mots-cl√©s se fait via l'IA
from . import gemini_client
from . import config
from . import utils

# Mots vides suppl√©mentaires courants en fran√ßais (√† compl√©ter)
FRENCH_STOPWORDS = set(STOPWORDS) | {
    'le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', '√†', 'et', 'est', 'il', 'elle',
    'on', 'nous', 'vous', 'ils', 'elles', 'ce', 'cet', 'cette', 'ces', 'mon', 'ma',
    'mes', 'ton', 'ta', 'tes', 'son', 'sa', 'ses', 'notre', 'nos', 'votre', 'vos',
    'leur', 'leurs', 'qui', 'que', 'quoi', 'dont', 'o√π', 'quand', 'comment', 'pourquoi',
    'avec', 'sans', 'pour', 'par', 'sur', 'sous', 'dans', 'hors', 'vers', 'depuis',
    'pendant', 'comme', 'si', 'ou', 'mais', 'donc', 'car', 'ni', 'plus', 'moins',
    'tr√®s', 'aussi', 'alors', 'afin', 'ainsi', 'apr√®s', 'avant', 'bien', 'chaque',
    'chez', 'contre', 'd√©j√†', 'depuis', 'encore', 'enfin', 'entre', 'jamais',
    'jusque', 'm√™me', 'parce', 'peut', 'peu', 'presque', 'puis', 'quel', 'quelle',
    'quels', 'quelles', 'sans', 'seulement', 'sont', 'sous', 'souvent', 'suivant',
    'tandis', 'tant', 'tel', 'telle', 'tels', 'telles', 'toujours', 'tout', 'toute',
    'toutes', 'tous', 'trop', 'tr√®s', 'vers', 'voici', 'voil√†', '√™tre', 'avoir', 'faire',
    'dire', 'pouvoir', 'aller', 'voir', 'vouloir', 'venir', 'falloir', 'devoir', 'savoir',
    'mettre', 'prendre', 'trouver', 'donner', 'parler', 'aimer', 'passer', 'penser',
    'regarder', 'utiliser', 'document', 'texte', 'fichier', 'contenu', 'page', 'section',
    'article', 'chapitre', 'selon', 'suite', 'figure', 'tableau', 'exemple', 'partie',
    'cas', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o',
    'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'
}


# @st.cache_data(show_spinner="Extraction des mots-cl√©s par l'IA...")
def extract_keywords_with_gemini(text: str,
                                 num_keywords: int = 10,
                                 model_name: str = config.DEFAULT_TEXT_MODEL_NAME) -> list[str] | None:
    """
    Extrait les mots-cl√©s principaux d'un texte en utilisant Gemini.

    Args:
        text (str): Le texte √† analyser.
        num_keywords (int): Le nombre de mots-cl√©s souhait√©.
        model_name (str): Le nom du mod√®le Gemini √† utiliser.

    Returns:
        list[str]: Une liste des mots-cl√©s extraits, ou None si erreur.
    """
    if not text:
        st.warning("Le texte pour l'extraction de mots-cl√©s est vide.", icon="‚ö†Ô∏è")
        return None

    # V√©rifier si le client Gemini est pr√™t
    if not gemini_client.configure_gemini():
         st.error("Impossible d'extraire les mots-cl√©s car le client Gemini n'est pas configur√©.", icon="‚ùå")
         return None

    # Construire le prompt
    prompt = f"""
    Analyse le document suivant et identifie les {num_keywords} mots-cl√©s ou expressions cl√©s les plus importants et repr√©sentatifs de son contenu principal.
    Ignore les mots courants et concentre-toi sur les termes sp√©cifiques et significatifs.

    --- DEBUT DOCUMENT ---
    {text[:8000]}
    --- FIN DOCUMENT ---

    Instructions de formatage :
    R√©ponds **UNIQUEMENT** avec une liste de mots-cl√©s s√©par√©s par des virgules. N'ajoute AUCUN autre texte, en-t√™te ou num√©rotation.

    Exemple de sortie attendue :
    mot-cl√© 1, expression cl√© 2, terme sp√©cifique 3, concept 4, ...

    Liste des mots-cl√©s :
    """ # L'IA devrait continuer apr√®s "Liste des mots-cl√©s :"

    # Appeler l'API Gemini
    response = gemini_client.generate_text(
        prompt=prompt,
        model_name=model_name,
        temperature=0.3, # Plus factuel pour l'extraction
        max_output_tokens=256 # Suffisant pour une liste de mots-cl√©s
    )

    if response:
        # Nettoyer la r√©ponse : supprimer les en-t√™tes potentiels et s√©parer par virgule
        response = response.strip()
        # Supprimer une √©ventuelle ligne d'en-t√™te restante
        if response.lower().startswith("liste des mots-cl√©s"):
            response = response.split(":", 1)[-1].strip()
        elif response.lower().startswith("voici les mots-cl√©s"):
             response = response.split(":", 1)[-1].strip()

        # S√©parer par virgule et nettoyer chaque mot-cl√©
        keywords = [kw.strip() for kw in response.split(',') if kw.strip()]
        if keywords:
            st.success(f"{len(keywords)} mots-cl√©s extraits par l'IA.", icon="üîë")
            return keywords
        else:
             st.warning("L'IA n'a pas retourn√© de mots-cl√©s dans le format attendu.", icon="ü§î")
             st.text_area("R√©ponse brute de l'IA (Mots-cl√©s)", response, height=100)
             return None
    else:
        st.error("L'extraction des mots-cl√©s par l'IA a √©chou√©.", icon="‚ùå")
        return None


@st.cache_data(show_spinner="G√©n√©ration du nuage de mots...")
def generate_word_cloud(text: str, max_words: int = 100) -> io.BytesIO | None:
    """
    G√©n√®re un nuage de mots √† partir du texte fourni.

    Args:
        text (str): Le texte source.
        max_words (int): Nombre maximum de mots √† afficher dans le nuage.

    Returns:
        io.BytesIO: Un buffer contenant l'image PNG du nuage de mots, ou None si erreur.
    """
    if not text:
        st.warning("Le texte pour le nuage de mots est vide.", icon="‚ö†Ô∏è")
        return None

    try:
        # Pr√©traitement simple du texte pour le nuage de mots
        # Convertir en minuscules et supprimer la ponctuation simple
        text_processed = re.sub(r'[^\w\s]', '', text.lower())

        wordcloud = WordCloud(
            width=800,
            height=400,
            background_color='white',
            stopwords=FRENCH_STOPWORDS,
            max_words=max_words,
            contour_width=1,
            contour_color='steelblue',
            colormap='viridis' # Choisir une palette de couleurs
        ).generate(text_processed)

        # Cr√©er la figure matplotlib
        plt.figure(figsize=(10, 5))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off') # Ne pas afficher les axes

        # Sauvegarder l'image dans un buffer m√©moire
        img_buffer = io.BytesIO()
        plt.savefig(img_buffer, format='png', bbox_inches='tight')
        img_buffer.seek(0) # Rembobiner le buffer pour la lecture
        plt.close() # Fermer la figure pour lib√©rer la m√©moire

        st.success("Nuage de mots g√©n√©r√©.", icon="‚òÅÔ∏è")
        return img_buffer

    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration du nuage de mots : {e}", icon="üî•")
        return None


@st.cache_data(show_spinner="Calcul des fr√©quences de mots...")
def get_word_frequencies(text: str, num_top_words: int = 20) -> list[tuple[str, int]] | None:
    """
    Calcule la fr√©quence des mots les plus courants dans le texte (apr√®s filtrage).

    Args:
        text (str): Le texte source.
        num_top_words (int): Le nombre de mots les plus fr√©quents √† retourner.

    Returns:
        list[tuple[str, int]]: Une liste de tuples (mot, fr√©quence), ou None si erreur.
    """
    if not text:
        st.warning("Le texte pour l'analyse de fr√©quence est vide.", icon="‚ö†Ô∏è")
        return None

    try:
        # Pr√©traitement : minuscules, suppression ponctuation, s√©paration mots
        text_processed = re.sub(r'[^\w\s]', '', text.lower())
        words = text_processed.split()

        # Filtrer les mots vides et les mots trop courts
        filtered_words = [word for word in words if word not in FRENCH_STOPWORDS and len(word) > 2]

        # Compter les fr√©quences
        word_counts = Counter(filtered_words)

        # Obtenir les N mots les plus fr√©quents
        most_common = word_counts.most_common(num_top_words)

        if most_common:
             st.success(f"Fr√©quence des {len(most_common)} mots les plus courants calcul√©e.", icon="üìä")
             return most_common
        else:
             st.warning("Aucun mot significatif trouv√© pour l'analyse de fr√©quence.", icon="ü§î")
             return None

    except Exception as e:
        st.error(f"Erreur lors du calcul de la fr√©quence des mots : {e}", icon="üî•")
        return None


def display_analysis_interface(text_available: bool, document_text: str | None):
    """
    Affiche l'interface pour les options d'analyse et les r√©sultats.

    Args:
        text_available (bool): Indique si du texte est disponible.
        document_text (str | None): Le texte du document charg√©.
    """
    st.subheader("5. Analyse & Insights")

    if not text_available or not document_text:
        st.info("Chargez un document pour activer les fonctionnalit√©s d'analyse.", icon="üìÑ")
        return

    analysis_options = st.multiselect(
        "Choisissez les analyses √† effectuer :",
        ["Extraction Mots-cl√©s (IA)", "Nuage de Mots", "Fr√©quence des Mots"],
        default=["Extraction Mots-cl√©s (IA)", "Nuage de Mots"], # Options par d√©faut
        key="analysis_selection"
    )

    run_analysis_button = st.button("Lancer l'Analyse", key="run_analysis_button", use_container_width=True)

    if run_analysis_button:
        st.session_state['analysis_results'] = {} # R√©initialiser les r√©sultats

        if "Extraction Mots-cl√©s (IA)" in analysis_options:
            keywords = extract_keywords_with_gemini(document_text, num_keywords=15)
            st.session_state['analysis_results']['keywords'] = keywords if keywords else "√âchec de l'extraction"

        if "Nuage de Mots" in analysis_options:
            wordcloud_img = generate_word_cloud(document_text, max_words=100)
            st.session_state['analysis_results']['wordcloud'] = wordcloud_img

        if "Fr√©quence des Mots" in analysis_options:
            frequencies = get_word_frequencies(document_text, num_top_words=20)
            st.session_state['analysis_results']['frequencies'] = frequencies

    # Afficher les r√©sultats stock√©s dans session_state
    if 'analysis_results' in st.session_state:
        results = st.session_state['analysis_results']
        st.markdown("---")
        st.markdown("### R√©sultats de l'Analyse")

        if 'keywords' in results:
            st.markdown("**Mots-cl√©s extraits par l'IA :**")
            if isinstance(results['keywords'], list):
                # Afficher sous forme de badges ou liste
                st.write(", ".join(f"`{kw}`" for kw in results['keywords']))
            else:
                st.error(results['keywords']) # Afficher le message d'√©chec

        if 'wordcloud' in results and results['wordcloud']:
            st.markdown("**Nuage de Mots :**")
            st.image(results['wordcloud'], caption="Nuage des mots les plus fr√©quents", use_column_width=True)

        if 'frequencies' in results and results['frequencies']:
            st.markdown("**Mots les plus fr√©quents :**")
            # Afficher sous forme de tableau ou graphique simple
            freq_data = results['frequencies']
            # Cr√©er un DataFrame pandas pour affichage facile
            try:
                import pandas as pd
                df_freq = pd.DataFrame(freq_data, columns=['Mot', 'Fr√©quence'])
                st.dataframe(df_freq, use_container_width=True, hide_index=True)

                # Optionnel : petit graphique √† barres
                fig, ax = plt.subplots(figsize=(10, 5))
                ax.barh(df_freq['Mot'], df_freq['Fr√©quence'], color='skyblue')
                ax.invert_yaxis() # Afficher le plus fr√©quent en haut
                ax.set_title('Top Mots par Fr√©quence')
                ax.set_xlabel('Fr√©quence')
                st.pyplot(fig)
                plt.close(fig) # Fermer la figure

            except ImportError:
                 st.warning("La biblioth√®que Pandas est n√©cessaire pour afficher le tableau des fr√©quences. Veuillez l'installer (`pip install pandas`).", icon="‚ö†Ô∏è")
                 # Afficher comme liste si pandas n'est pas l√†
                 for word, freq in freq_data:
                     st.write(f"- `{word}` : {freq}")
            except Exception as e:
                 st.error(f"Erreur lors de l'affichage des fr√©quences : {e}", icon="üî•")


# --- Int√©gration dans app.py ---
# doc_text = st.session_state.get('document_text', None)
# display_analysis_interface(text_available=bool(doc_text), document_text=doc_text)

